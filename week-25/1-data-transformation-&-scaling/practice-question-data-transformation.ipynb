{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b53844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22d261",
   "metadata": {},
   "source": [
    "# Find Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In the Big mart dataset, you have separated the information for Items and outlets. Now your task is to find the correlation \n",
    "between \"ItemOutletSales\" and all other features of the \"split_items\" dataset.\n",
    "Your task is to split the big mart dataset based on \"Items\" and \"Outlet\" information as discussed in the video. \n",
    "Then find the feature having a correlation greater than 0.5 in the \"splititems\" dataset with the feature \"ItemOutlet_Sales\".\n",
    "\n",
    "Expected Output\n",
    "Print the feature with a correlation greater than 0.5 with \"Item_Outlet_Sales\" in the \"split_items\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f871fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_MRP\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bigmart.csv')\n",
    "df['rowno'] = np.arange(len(df))\n",
    "df_items = df.filter(['rowno','Item_Identifier','Item_Weight','Item_Fat_Content','Item_Visibility','Item_MRP','Item_Outlet_Sales'])\n",
    "df_items.corr()\n",
    "\n",
    "print('Item_MRP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5b4602",
   "metadata": {},
   "source": [
    "# All Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372de01",
   "metadata": {},
   "outputs": [],
   "source": [
    "You have been provided with two datasets:\n",
    "data1 = {\n",
    "  \"name\": [\"Sally\", \"Mary\", \"John\"],\n",
    "  \"age\": [50, 40, 30]}\n",
    "\n",
    "data2 = {\n",
    "  \"name\": [\"Sally\", \"Peter\", \"Micky\"],\n",
    "  \"age\": [77, 44, 22]\n",
    "}\n",
    "\n",
    "Your task is to merge these two datasets in such a way that all the rows of both the dataset are present in the merged dataset.\n",
    "\n",
    "Expected output\n",
    "Print the number of unique values present in the “name” column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fcfa317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "data1 = {\n",
    "  \"name\": [\"Sally\", \"Mary\", \"John\"],\n",
    "  \"age\": [50, 40, 30]}\n",
    "\n",
    "data2 = {\n",
    "  \"name\": [\"Sally\", \"Peter\", \"Micky\"],\n",
    "  \"age\": [77, 44, 22]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "merged = pd.merge(df1,df2,on=['name','age'],how='outer')\n",
    "print(merged['name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d885ad2c",
   "metadata": {},
   "source": [
    "# Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201505a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "You have been given two data frames.\n",
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "\n",
    "df2 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                'salary': [70000, 80000, 120000, 90000]})\n",
    "Problem Statement\n",
    "You need to merge these two datasets. Here the employee for df1 is similar to the name for df2. \n",
    "Also, you need to remove the name column from the merged data frame.\n",
    "\n",
    "Expected Output\n",
    "Print the shape of the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f70cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "\n",
    "df2 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                'salary': [70000, 80000, 120000, 90000]})\n",
    "\n",
    "df2.rename(columns = {'name':'employee'}, inplace = True)\n",
    "merged = pd.merge(df1,df2,on='employee',how='outer')\n",
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da638b9",
   "metadata": {},
   "source": [
    "# Filter Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "The B6 airline has been struggling with handling the amount of traffic that comes to the Delhi and Banglore airports. \n",
    "They need to make a decision if they need to add one more aeroplane to these airports. You have been provided with the \n",
    "airline dataset. Your task is to filter out this dataset based on the following conditions:\n",
    "1. Either the destination is DEL or the origin is BLR.\n",
    "2. Air time should be less than 5 hrs.\n",
    "3. Carrier should be B6.\n",
    "\n",
    "The dataset is given below:\n",
    "airline = {\n",
    "    \"Carrier\": [\"B6\", \"WW\", \"B6\", \"B6\", \"WN\", \"WW\", \"B6\"],\n",
    "    \"Origin\": [\"BLR\", \"JAI\", \"SAG\", \"SXR\", \"BLR\", \"JLR\", \"DLI\"],\n",
    "    \"Destination\": [\"DEL\", \"DEL\", \"HYD\", \"DEL\", \"JAI\", \"KLH\", \"RPR\"],\n",
    "    \"Time\": [3, 2, 5, 3, 6, 4, 3]\n",
    "}\n",
    "\n",
    "Expected Output\n",
    "Print the sum of air_time from the filtered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0885edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airline = {\n",
    "    \"Carrier\": [\"B6\", \"WW\", \"B6\", \"B6\", \"WN\", \"WW\", \"B6\"],\n",
    "    \"Origin\": [\"BLR\", \"JAI\", \"SAG\", \"SXR\", \"BLR\", \"JLR\", \"DLI\"],\n",
    "    \"Destination\": [\"DEL\", \"DEL\", \"HYD\", \"DEL\", \"JAI\", \"KLH\", \"RPR\"],\n",
    "    \"Time\": [3, 2, 5, 3, 6, 4, 3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(airline)\n",
    "filtered_data = df[((df['Origin']=='BLR') | (df['Destination']=='DEL')) & (df['Time']<5) & (df['Carrier']=='B6')]\n",
    "print(filtered_data['Time'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0828a884",
   "metadata": {},
   "source": [
    "# Dairy Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "For the big mart dataset, you have been given a task to find the average of the MRP for the \"Dairy\" products which are present \n",
    "in the \"Medium\" size outlets.\n",
    "\n",
    "Expected Output\n",
    "Print the average MRP for Diary products in the medium size outlets rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d99c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.51\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bigmart.csv')\n",
    "filtered_data = df[(df['Item_Type']=='Dairy') & (df['Outlet_Size']=='Medium')]\n",
    "print(round(filtered_data['Item_MRP'].mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7635e",
   "metadata": {},
   "source": [
    "# Highest Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "For the big mart dataset, your manager wants to make a decision on opening a new outlet, she gave you the task to provide her \n",
    "with the data grouped by the location of the previously opened outlets and the type of outlet and \n",
    "find out the average itemoutletsales for each of these groups.\n",
    "\n",
    "Expected output\n",
    "Print the highest sum of sales based on the \"Outlet Type\" and the \"Outlet Location Type\". \n",
    "Convert the output to the integer type having a floor value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ab704c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6472313\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bigmart.csv')\n",
    "# df.groupby(['Outlet_Location_Type','Outlet_Type']).agg({'Item_Outlet_Sales':np.mean})\n",
    "s = df.groupby(['Outlet_Location_Type','Outlet_Type']).agg({'Item_Outlet_Sales':np.sum})\n",
    "print(int(s['Item_Outlet_Sales'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c2fc3",
   "metadata": {},
   "source": [
    "# Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "An investor is interested in funding your company but first requests some sales data. Your manager has assigned you to display \n",
    "the records \"Small\" outlet size. Another requirement is that only \"Tier 1\" outlet locations are needed.\n",
    "\n",
    "Expected Output\n",
    "Print the highest sum of Item_Outlet_Sales grouped by \"Outlet_Identifier\", filtered by Outlet_Location_Type and Outlet_Size.\n",
    "\n",
    "Convert the answer to the int data type with floor value,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77edf97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2118395\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bigmart.csv')\n",
    "filter_data = df[(df['Outlet_Size']=='Small') & (df['Outlet_Location_Type']=='Tier 1')]\n",
    "s = filter_data.groupby('Outlet_Identifier').agg({'Item_Outlet_Sales':np.sum})\n",
    "print(int(s['Item_Outlet_Sales'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28200cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e06962f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed17984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108265bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07199c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb74257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174757b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ca80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
